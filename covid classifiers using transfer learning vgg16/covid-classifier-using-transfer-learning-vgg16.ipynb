{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1347344,"sourceType":"datasetVersion","datasetId":783964}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Split dataset and equalize training/validation sets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom tqdm.notebook import tqdm\nimport random\nimport shutil\n\n\ndef split_list(data, split_ratio=0.8):\n    # Calculate the index to split the list\n    split_index = int(len(data) * split_ratio)\n    \n    # Shuffle the list randomly\n    random.shuffle(data)\n    \n    # Split the list based on the calculated index\n    train_data = data[:split_index]\n    test_data = data[split_index:]\n    \n    return train_data, test_data\n\ndef delete_files_in_directory(directory_path):\n    # Get the list of files in the directory\n    files = os.listdir(directory_path)\n\n    # Iterate through the files and delete each one\n    for file_name in tqdm(files):\n        file_path = os.path.join(directory_path, file_name)\n        try:\n            if os.path.isfile(file_path):\n                os.remove(file_path)\n        except Exception as e:\n            print(f\"Error deleting {file_path}: {e}\")\n            \n    shutil.rmtree(directory_path)\n\n# Example usage:\n# directory_to_clear = '/kaggle/working/val'\n# delete_files_in_directory(directory_to_clear)\n# print('Done')\n\ndata_path = '/kaggle/input/dlai3-hackathon-phase3-covid19-cxr-challenge/DLAI3_Phase3'\n\nos.mkdir('/kaggle/working/train')\nos.mkdir('/kaggle/working/val')\n\nfor class_name in os.listdir(data_path):\n    if not os.path.isdir(os.path.join(data_path, class_name)):\n        continue\n    print('Processing: ', class_name)\n    images_path = os.path.join(data_path, class_name)\n    train_files, val_files = split_list(os.listdir(images_path), 0.8)\n    train_ds = f'/kaggle/working/train/{class_name}'\n    os.mkdir(train_ds)\n    for file_name in tqdm(train_files):\n        shutil.copy(os.path.join(images_path, file_name), os.path.join(train_ds, file_name))\n    val_ds = f'/kaggle/working/val/{class_name}'\n    os.mkdir(val_ds)\n    for file_name in tqdm(val_files):\n        shutil.copy(os.path.join(images_path, file_name), os.path.join(val_ds, file_name))","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:55:43.322632Z","iopub.execute_input":"2024-01-17T14:55:43.323266Z","iopub.status.idle":"2024-01-17T14:57:06.780523Z","shell.execute_reply.started":"2024-01-17T14:55:43.323225Z","shell.execute_reply":"2024-01-17T14:57:06.779544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_minimum_files_count(directory):\n    # Get the list of files in the directory\n    files = os.listdir(directory)\n    \n    # Return the count of files in the directory\n    return len(files)\n\ndef equalize_folders(file_root):\n    # Get a list of all subdirectories in the given root directory\n    subdirectories = [d for d in os.listdir(file_root) if os.path.isdir(os.path.join(file_root, d))]\n    \n    if not subdirectories:\n        print(\"No subdirectories found.\")\n        return\n    \n    # Find the minimum number of files among all subdirectories\n    min_files_count = min(find_minimum_files_count(os.path.join(file_root, subdir)) for subdir in subdirectories)\n    \n    # Equalize the number of files in each subdirectory\n    for subdir in subdirectories:\n        subdir_path = os.path.join(file_root, subdir)\n        files = os.listdir(subdir_path)\n        \n        while len(files) > min_files_count:\n            # Remove random file\n            random_file = os.path.join(subdir_path, random.choice(files))\n            os.remove(random_file)\n            files.remove(os.path.basename(random_file))\n            print(f\"Deleted: {random_file}\")\n\n# Example usage:\n# root_directory = 'path/to/root'\n# equalize_folders(root_directory)\n\n\nfor sub in ['train', 'val']:\n    sub_folder = f'/kaggle/working/{sub}'\n    equalize_folders(sub_folder)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:57:32.934538Z","iopub.execute_input":"2024-01-17T14:57:32.935245Z","iopub.status.idle":"2024-01-17T14:57:32.943644Z","shell.execute_reply.started":"2024-01-17T14:57:32.935206Z","shell.execute_reply":"2024-01-17T14:57:32.942553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1> Start building model ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.applications.vgg16 import preprocess_input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-17T15:01:14.980359Z","iopub.execute_input":"2024-01-17T15:01:14.980708Z","iopub.status.idle":"2024-01-17T15:01:14.986130Z","shell.execute_reply.started":"2024-01-17T15:01:14.980679Z","shell.execute_reply":"2024-01-17T15:01:14.985233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_size = (128,128)\ninput_shape = (128, 128, 3)\nbase_dir = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:58:12.467013Z","iopub.execute_input":"2024-01-17T14:58:12.467600Z","iopub.status.idle":"2024-01-17T14:58:12.471681Z","shell.execute_reply.started":"2024-01-17T14:58:12.467569Z","shell.execute_reply":"2024-01-17T14:58:12.470850Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_gen = ImageDataGenerator(\n    rescale=1./255\n)\nval_gen = ImageDataGenerator(rescale=1./255)\ntest_gen = ImageDataGenerator(rescale=1./255)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:58:17.927391Z","iopub.execute_input":"2024-01-17T14:58:17.927750Z","iopub.status.idle":"2024-01-17T14:58:17.932824Z","shell.execute_reply.started":"2024-01-17T14:58:17.927720Z","shell.execute_reply":"2024-01-17T14:58:17.931665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = train_gen.flow_from_directory(base_dir + 'train',target_size=input_size,seed=42)\nval_data = val_gen.flow_from_directory(base_dir + 'val',target_size=input_size,seed=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:58:34.469085Z","iopub.execute_input":"2024-01-17T14:58:34.469528Z","iopub.status.idle":"2024-01-17T14:58:34.517198Z","shell.execute_reply.started":"2024-01-17T14:58:34.469502Z","shell.execute_reply":"2024-01-17T14:58:34.516478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16 = VGG16(input_shape=input_shape, weights='imagenet', include_top=False)\nfor layer in vgg16.layers:\n    layer.trainable = False\nvgg16.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T14:59:07.402260Z","iopub.execute_input":"2024-01-17T14:59:07.403043Z","iopub.status.idle":"2024-01-17T14:59:10.054848Z","shell.execute_reply.started":"2024-01-17T14:59:07.403007Z","shell.execute_reply":"2024-01-17T14:59:10.053968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.9:\n            print(\"\\nReached 90% accuracy so cancelling training!\")\n            self.model.stop_training = True","metadata":{"execution":{"iopub.status.busy":"2024-01-17T15:01:21.709378Z","iopub.execute_input":"2024-01-17T15:01:21.710315Z","iopub.status.idle":"2024-01-17T15:01:21.716245Z","shell.execute_reply.started":"2024-01-17T15:01:21.710272Z","shell.execute_reply":"2024-01-17T15:01:21.715366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = myCallback()\n\noutput = Flatten()(vgg16.output)\noutput = Dense(500, activation='relu')(output)\noutput = Dense(100, activation='relu')(output)\noutput = Dropout(0.5)(output)\noutput = Dense(3, activation='softmax')(output)\nmodel = Model(inputs=vgg16.input, outputs=output)\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T15:01:50.496076Z","iopub.execute_input":"2024-01-17T15:01:50.496406Z","iopub.status.idle":"2024-01-17T15:01:50.624214Z","shell.execute_reply.started":"2024-01-17T15:01:50.496383Z","shell.execute_reply":"2024-01-17T15:01:50.623386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_data,\n                    batch_size=32,\n                    epochs=10,\n                    validation_data=val_data,\n                    callbacks = [callbacks])","metadata":{"execution":{"iopub.status.busy":"2024-01-17T15:02:52.037975Z","iopub.execute_input":"2024-01-17T15:02:52.038321Z","iopub.status.idle":"2024-01-17T15:04:53.428061Z","shell.execute_reply.started":"2024-01-17T15:02:52.038296Z","shell.execute_reply":"2024-01-17T15:04:53.427101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h1>Predict new samples","metadata":{}},{"cell_type":"code","source":"class_names = train_data.class_indices\nclass_names","metadata":{"execution":{"iopub.status.busy":"2024-01-17T15:05:22.138762Z","iopub.execute_input":"2024-01-17T15:05:22.139656Z","iopub.status.idle":"2024-01-17T15:05:22.146246Z","shell.execute_reply.started":"2024-01-17T15:05:22.139624Z","shell.execute_reply":"2024-01-17T15:05:22.145305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.utils import load_img, img_to_array\nimport matplotlib.pyplot as plt\n\n\npath = '/kaggle/working/val/THORAXDISEASE/person753_virus_1378.jpeg'\nimg = load_img(path, target_size=(128, 128))\nx = img_to_array(img)\nx /= 255\nx = np.expand_dims(x, axis=0)\n\nimages = np.vstack([x])\npredictions = model.predict(images, batch_size=10)\n\n# Get the predicted class index\npredicted_class_index = np.argmax(predictions)\n\n# Get the predicted class label from the 'gen' variable\npredicted_class = list(class_names.keys())[list(class_names.values()).index(predicted_class_index)]\n\n# Print the prediction\nprint(\"Predicted class:\", predicted_class)\n# print(\"Class probabilities:\", predictions)\n\nplt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-17T15:06:41.742687Z","iopub.execute_input":"2024-01-17T15:06:41.743290Z","iopub.status.idle":"2024-01-17T15:06:42.189236Z","shell.execute_reply.started":"2024-01-17T15:06:41.743242Z","shell.execute_reply":"2024-01-17T15:06:42.188045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}